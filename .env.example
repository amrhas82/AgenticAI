# Example environment configuration
# Copy to .env and adjust as needed

# OLLAMA: Host where the Ollama server runs (containers use host.docker.internal)
OLLAMA_HOST=http://localhost:11434

# Embedding model and dimension (used by VectorDB)
EMBED_MODEL=nomic-embed-text
EMBED_DIM=768

# MCP client endpoint (optional)
MCP_URL=http://localhost:8080

# Optional OpenAI API key (can also be provided in UI)
# OPENAI_API_KEY=
