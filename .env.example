# AI Agent Playground Environment Configuration
# Copy this file to .env and fill in your values

# ============================================
# Database Configuration
# ============================================
DATABASE_URL=postgresql://ai_user:ai_password@postgres:5432/ai_playground

# ============================================
# Ollama Configuration (Local LLMs)
# ============================================
# Ollama host URL - adjust based on your setup:
# - Local (no Docker): http://localhost:11434
# - Docker on Linux: http://host.docker.internal:11434
# - Docker on Mac/Windows: http://host.docker.internal:11434
OLLAMA_HOST=http://localhost:11434

# Embedding model for vector database (must be pulled via ollama first)
EMBED_MODEL=nomic-embed-text

# Embedding dimension (768 for nomic-embed-text, 384 for all-minilm, etc.)
EMBED_DIM=768

# ============================================
# MCP (Model Context Protocol) Configuration
# ============================================
# Klavis MCP self-hosted URL
# Default assumes running locally on port 8080
# See: https://github.com/Klavis-AI/klavis
MCP_URL=http://localhost:8080

# MCP API key for authentication (optional)
MCP_API_KEY=

# ============================================
# External AI Provider API Keys
# ============================================
# OpenAI API Key (for GPT models)
# Get yours at: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Anthropic API Key (for Claude models)
# Get yours at: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# Google Gemini API Key
# Get yours at: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=

# Cohere API Key (for embeddings and reranking)
# Get yours at: https://dashboard.cohere.com/api-keys
COHERE_API_KEY=

# Hugging Face API Token (for hosted inference)
# Get yours at: https://huggingface.co/settings/tokens
HUGGINGFACE_API_TOKEN=

# ============================================
# Vector Database Configuration
# ============================================
# Path for JSON-based vector store fallback (when Postgres unavailable)
VECTOR_JSON_PATH=data/memory/vector_store.json

# ============================================
# Application Settings
# ============================================
# Enable debug mode (shows more verbose logging)
DEBUG=false

# Maximum conversation history to keep in memory
MAX_CONVERSATION_HISTORY=10

# Auto-save conversations
AUTO_SAVE_CONVERSATIONS=true

# ============================================
# Advanced Settings
# ============================================
# Chunk size for document processing (in words)
CHUNK_SIZE=1000

# Chunk overlap for document processing (in words)
CHUNK_OVERLAP=200

# Similarity threshold for RAG (0.0-1.0)
SIMILARITY_THRESHOLD=0.7

# Maximum results to return from vector search
MAX_RAG_RESULTS=5

# ============================================
# Optional: Custom Model Endpoints
# ============================================
# If using custom endpoints for external models
# CUSTOM_MODEL_ENDPOINT=

# ============================================
# Security Settings
# ============================================
# Secret key for API authentication (generate with: openssl rand -hex 32)
# API_SECRET_KEY=

# Allowed origins for CORS (comma-separated)
# ALLOWED_ORIGINS=http://localhost:8501,http://localhost:3000

# ============================================
# API Key Management (for external agents)
# ============================================
# Enable API key authentication for external agents
ENABLE_API_AUTH=false

# Master API key for administrative access (generate strong key)
MASTER_API_KEY=

# Path for JSON-based API key storage (fallback when Postgres unavailable)
API_KEYS_JSON_PATH=data/memory/api_keys.json

# ============================================
# Performance & Resource Settings
# ============================================
# Request timeout in seconds
REQUEST_TIMEOUT=30

# Maximum file upload size in MB
MAX_UPLOAD_SIZE_MB=50

# Number of worker threads for document processing
PROCESSING_WORKERS=4

# ============================================
# Feature Flags
# ============================================
# Enable experimental features
ENABLE_EXPERIMENTAL=false

# Enable code execution in agents (security risk if exposed to untrusted users)
ENABLE_CODE_EXECUTION=true

# Enable RAG by default for new chats
ENABLE_RAG_DEFAULT=false

# Enable MCP integration
ENABLE_MCP=true
